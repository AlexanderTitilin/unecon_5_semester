\documentclass[14pt]{extarticle}
\usepackage{fontspec}
\usepackage[russian, english]{babel}
\setmainfont{Times New Roman}
\usepackage{amssymb}
\usepackage{setspace}
\onehalfspacing
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{indentfirst}
\setlength{\parindent}{1.25cm}
\usepackage[right=10mm,left=30mm,top=20mm,bottom=20mm]{geometry}
\newcommand{\bm}[1]{ \left.#1\right|}
\newtheorem{theorem}{Теорема}
\newtheorem{definition}{Определение}
\newtheorem{corollary}{Замечание}
\newtheorem{lemma}[theorem]{Лемма}
\title{Матстата}
\author{}
\date{}
\begin{document}
	\maketitle
	\section{}
	Открыть старый канспект, повторить распределения, несобственные интегралы.
	\section{Отступление матан. Гамма-функция Эйлера}
	\begin{eqnarray}
		\Gamma(y) = \int\limits_{0}^{+\infty}  t^{y-1}e^{-t}dt,\\ f(t) = t^{y-1}e^{-t}
	\end{eqnarray}
	Рассмотрим $t^{y+1} e^{-t} = \frac{t^{y+1}}{et} \to 0,$ при $t \to + \infty$  $\implies$  $\exists  A: \forall t \ge  A ~ t^{y+1} e^{-t} < 1 \implies f(t) = t^{y-1} e^{-t} < \frac{1}{t^2}$
	\[
	\int\limits_{0}^{+\infty}  f(t) dt = \int\limits_{0}^{A} f(t)  dt + \int\limits_{A}^{+\infty}  f(t) dt = I_1 + I_2
	.\] 
	$I_2$ сходится при $\forall  y \in \mathbb{R}$, по первому признаку сравнения с $\int\limits_{A}^{+\infty} g(t) dt , g(t) = \frac{1}{tst}  $
	
	Рассмотрим $I_1$  при $y < 1$ это несобственный интеграл
	 \[
		 t^{y-1}e^{-t}< t^{y-1}
	.\] 
	$\int\limits_{0}^{A} \frac{dt}{t^{1- y}}  $ сходится при $y > 0$ ,  $1- y < 1$
	
	\textbf{Вывод}. При $y>0$  $\Gamma(y) =  \int\limits_{0}^{+\infty} t^{y-1}e^{-1} dt $
	
	Без доказательства для $n \in \mathbb{N}$
	\begin{equation}
		\Gamma(n + \frac{1}{2}) = 2^{-n} \sqrt{\pi} (2n -1)!!
	\end{equation}
	\begin{equation}
		\Gamma(y+1) \int\limits_{0}^{+\infty}  t^{y}e^{-t}dt
		- \int\limits_{0}^{+\infty}  t^{y} d e^{-t}=
		-t^{y}e^{-t} \mid_{0}^{+\infty} + y \int\limits_{0}^{+\infty} y^{-1} e^{-t} dt = 0 + y \Gamma(y)
	\end{equation}
	\begin{equation}
		\Gamma(y+1) = y \Gamma(y)
	\end{equation}
\begin{eqnarray}
	\Gamma(1) = \int\limits_{0}^{+\infty}  e^{-t} dt = -e^{-t}\mid_{0}^{+\infty}\\
	\Gamma(2) = 1*\Gamma(1) =1\\
	\Gamma(3) = 2*\Gamma(2) = 2\\
	\Gamma(n+1) = n!
\end{eqnarray}
Можно показать, что Гамма функция дифференцируема
\begin{equation}
		\Gamma(\frac{1}{2}) = -\frac{1}{2}\Gamma(-\frac{1}{2})
		\implies \Gamma(-\frac{1}{2}) = -2 \Gamma(\frac{1}{2})
\end{equation}
Но 
\begin{equation}
	\Gamma(0) = + \infty , ~ \int\limits_{0}^{A}   t^{-1}e^{-t} = \int\limits_{0}^{A}  \frac{dt}{t^{et}}
\end{equation}
По второму признаку сравнения это расходится
\[
\lim_{t \to 0+0}  \frac{1}{te^{t}} : \frac{1}{t} = \lim_{t \to 0+0} 1 \in (0;+\infty)
.\] 
\textbf{Вывод.} $\Gamma$ функцию можно продолжить на  $\mathbb{R}^{-}$ ккроме целых точек
\begin{equation}
	C_{n}^{k} = \frac{n!}{k! (n-k)!} = \frac{\Gamma(n+1)}{\Gamma(k+1)\Gamma(n - k + 1)}
\end{equation}
Мы расшили понтие числа сочений
 \begin{equation}
 	C_{\alpha}^{\beta} = 
	\frac{\Gamma(\alpha + 1)}{\Gamma(\beta + 1) \Gamma(\alpha -\beta + 1)} ,  \alpha,\beta \in \mathbb{R} \setminus \mathbb{Z}^{-}
 \end{equation}
 \section{Закон распределения Лапласа (двойное экспонициальное распределение)}
 Он применяетс для моделирования обработки сигналов, в моделировании биологических процессов, экономике и финансах

 Это распределние НСВ $X$ с плотностью
  \begin{equation}
 	f(x) = \frac{\lambda}{2} e^{-\lambda |x|}, x \in \mathbb{R},\lambda > 0
 \end{equation}
 \begin{equation}
 	F(x) =
	\begin{cases}
		\frac{1}{2}e^{\lambda x} , x \le 0\\
		1 - \frac{1}{2}e^{-\lambda x}
	\end{cases}
 \end{equation}
 \begin{equation}
	 x\le  0,
 	F(x) = \int\limits_{-\infty}^{x}   \frac{\lambda}{2} e^{\lambda t} dt = \frac{1}{2} e^{\lambda t} \mid_{-\infty}^{x} = \frac{1}{2}(e^{\lambda x} - 0)
 \end{equation}
 \begin{equation}
 	x > 0 =  F(0)  + \int\limits_{0}^{x}
 \end{equation}
 из вида $f(x)$ :  $Mo(X) = Me(X) = M(X) = 0$
 \begin{eqnarray}
 	D(X) = M(X^2) = 
	\int\limits_{-\infty}^{+\infty}  x^2 f(x) dx = 
	2 \int\limits_{-\infty}^{\infty} x^2 * \frac{\lambda}{2} e^{-\lambda x} dx = \dots = (- x^2 +\frac{2}{\lambda} x
	+ \frac{2}{\lambda^2}) e^{-\lambda x} \mid_{0}^{+\infty}\\
 \end{eqnarray}
 \begin{equation}
  = \frac{2}{\lambda^2}
 \end{equation}
 \section{Распредение Вейбула}
 Это распредение имеют времена безотказной работы технческих устройтв.
 В таких значениях важной характеристикой является интенсивность отказа $k(t)$ 
  \begin{equation}
	  k(t) = - \frac{ [P(X \ge  t)]'}{P(X \ge  t)}, k(t) = \frac{f(t)}{1 - F(t)}
 \end{equation}
 Получили диффур. Это УРП, решаем элементарно
 \begin{eqnarray}
 	k(t) = \frac{y'}{1 - y}\\
	k(t) dt = \frac{dt}{1 -y}\\
	-\int k(t)dt + C = \ln{( 1-y )}\\
	y = 1 - e^{-\int k(t) dt + C}\\
	y(0) = 0 \implies y = 1 -e^{-\int\limits_{0}^{x} k(t)dt }
 \end{eqnarray}
 Во многих случаях график $k(t)$ имеет следущий вид
  \begin{enumerate}
 	\item период обкатки
	\item период нормальной эксплуатации
	\item период старения
 \end{enumerate}
 Рассмотрим класс степенных зависимостей $k(t)=\lambda \alpha t^{`-1`}$ где $\lambda > 0 , \alpha > 0$ некоторые числовые параметры.
 Периодам 1,2,3 отвечают  $\alpha < 1,\alpha =1, \alpha>1$ соответственно

 Функция распеделения
 \begin{equation}
 	F_{X}(x) = 1 - e^{- \frac{0}{x} \lambda \alpha t^{\alpha - 1} dt} = 1- e^{\lambda t^{\alpha}} \mid_{0}^{x} = 1 - e^{-\lambda x^{\alpha}}
 \end{equation}
 Плотность
 \begin{equation}
 	f_{X}(x) (F_{X}(x))' = \lambda \alpha x^{\alpha - 1} e^{-\lambda x^{\alpha}}
 \end{equation}
 При $a = 1$ получим  $E(\lambda)$ , при  $\alpha = 2$ получим распределениие Рэлея  $f(x) = 2\lambda x e^{-\lambda x^2}$
 \subsection{Числовые характеристики Распределения Вейбулла}
 \begin{equation}
 	M(X) = \lambda^{-\frac{1}{\alpha}} \Gamma(1+  \frac{1}{\alpha})
 \end{equation}
 \begin{equation}
 	M(X) = \int\limits_{0}^{+\infty}  x \alpha * \lambda x^{\alpha - 1} e^{-\lambda x^{\alpha}} dx = \int\limits_{0}^{+\infty} \lambda^{-\frac{1}{\alpha}} t^{\frac{1}{\alpha}} e^{-t} dt = \lambda^{-\frac{1}{\alpha}} \Gamma(1 + \frac{1}{\alpha})
 \end{equation}
 \begin{equation}
	 M(X^2) = \lambda^{-\frac{-2}{\alpha}} \Gamma(1 + \frac{2}{\alpha}) \implies D(X) = \lambda^{-\frac{2}{\alpha}}  (
	 	\Gamma(1 + \frac{2}{\alpha}) - \Gamma^2(1 + \frac{1}{\alpha})
	 )
 \end{equation}
 \begin{equation}
	 \text{Me} (X) = (\frac{1}{\lambda} \ln{2}) ^{\frac{1}{\alpha}}
 \end{equation}
 \begin{equation}
 	Mo(X) = 
	\begin{cases}
		0, \alpha \le  1\\
		(\frac{\alpha - 1}{\lambda \alpha})^{\frac{1}{\alpha}}, \alpha > 1
	\end{cases}
	f'(x )  = 0
 \end{equation}
 \section{Гамма-распеделение}
 Оно используется для описание времен безотказной работы различных 
 технических устройств

 Его имеет НСВ $X = \gamma(a,b)$ с плотностью
  \begin{equation}
 	f(x) =
	\begin{cases}
		\frac{b^{a}}{\Gamma(a)} x^{a - 1} e^{-b x} ,x>0\\
		0 , x \le  0
	\end{cases}
 \end{equation}
 где $a > 0$ параметр формы,  $b > 0$ параметр масштаба
 \subsection{Свойства}
  \begin{enumerate}
 	\item $b * \gamma(a,b) = \gamma(a,1)$ 
	\[
	f_{\alpha X + \beta}(x) = f_{X}( \frac{x -  b}{a} )*\frac{1}{|a|} \implies
	.\] 
	\[
		f_{b \gamma(a,b)}(x) = f_{\gamma_{a,b}}(\frac{x}{b})\frac{1}{b} = \frac{b^{a}}{\Gamma(a)} \frac{x^{a -1}}{b^{a-1} }*e^{-b \frac{x}{b}} * \frac{1}{b} = \frac{1}{\Gamma(a)} x^{\alpha-1}e^{-x} = f_{\gamma(a,1)}(x)
	.\] 
\item Если случайные величины независимы
\item $a = \frac{m}{2},b = \frac{1}{2}$ получм $\chi^{2}_{m}$,$a =1$ получим экспонициальное
 \end{enumerate}
 \subsection{Функция распределение}
 \begin{equation}
 	F_{\gamma(a,b)}) (x) = \frac{1}{\Gamma(a)} \int\limits_{0}^{bx}   \tau^{a - 1} e^{-\tau}
 \end{equation}
 \subsection{Числовые Характеристики}
 \begin{equation}
 	M(\gamma(a,b)) = \frac{b^{a}}{\Gamma(a)} \int\limits_{0}^{+\infty} x * x^{a-1}  e^{-bx} dx =_{t=bx} \frac{b^{a}}{\Gamma(a)}\int\limits_{0}^{+\infty}   \frac{t^{a}}{b^{a}} e^{-t} * \frac{dt}{b} = \frac{\Gamma(a+1)}{b\Gamma(a)} = \frac{a \Gamma(a)}{b \Gamma(a)}= \frac{a}{b}
 \end{equation}
 \begin{equation}
 	D(\gamma(a,b)) = \frac{a(a+1)}{b^{2}} - (\frac{a}{b})^{2}=
	\frac{a}{b^2}
 \end{equation}
 \begin{equation}
 	Mo = \frac{a - 1}{b} ,a\ge 1
 \end{equation}
\begin{equation}
 	f'(x) = 0
\end{equation}
\section{Некоторые другие законы}
\subsection{Распределение Парето}
\begin{equation}
f(x) + \frac{\alpha	}{c_0} (\frac{c_0}{x})^{\alpha +1}, x\ge  c_0, \alpha >0 ,c_0 >0
\end{equation} 
Связано с налогами (доход превосходит $c_0$)
\begin{equation}
F(x) = 1 - \left(\frac{c_0}{x}\right)^{\alpha}
\end{equation} 
\begin{equation}
\int\limits_{-\infty}^{+\infty} x * f(x) dx =
\int\limits_{-\infty}^{+\infty} \frac{\alpha}{c_0} \left(
\frac{c_0}{x}\right)^{\alpha} = 
\int\limits_{c_0}^{+\infty}  \frac{\alpha}{c_0} 
(\frac{c_0}{x})^{\alpha} =
\frac{\alpha}{c_0} (\lim_{x \to \infty} )
\end{equation} 
\begin{equation}
M(x^2) = 
\frac{\alpha}{c_0} * c^{\alpha+1} \int\limits_{c_0}^{+\infty}   (x)^{-\alpha - 1} dx = 
\alpha c^{\alpha} \bm{\frac{1}{- \alpha} x^{-\alpha}}_{c_0}^{+\infty}
\end{equation} 
\begin{equation}
	1 - (\frac{c_0}{x})^{\alpha} =
	 \frac{1}{2}
\end{equation} 
\begin{equation}
x^{\alpha} = 2c_0^{\alpha}
\end{equation} 
\subsection{Рапределение Коши}
\begin{equation}
f(x) = \frac{c}{\pi (c^2 + (x - \alpha)^2)}, x \in \mathbb{R}
\end{equation} 
\begin{equation}
\int \frac{c}{\pi (c^2 + (x - \alpha)^2)} d(x - \alpha) =
\frac{c}{\pi} \left(\frac{1}{c} \arctan{\frac{x - \alpha}{c}}\right) + c = \frac{1}{\pi} \arctan{\frac{x - \alpha}{c}} + c
\end{equation} 
\subsection{Свойства устойчивости рапределения Коши}
\begin{enumerate}
	\item Если случайная величина
		$X$ распределена по закону Коши с параметрами
		 $c,\alpha$ ,
		 тогда  $Y = b_0 + b_1 X$ 
		 имеет распределение с параметрами $c' = |b_1| c$, $\alpha' = b_1 \alpha + b_0$

\begin{equation}
f_{a X + b} (x) = f_{X} \left(\frac{x-b}{a}\right) * \frac{1}{|a|}
\end{equation} 
\item Если есть независимые случайно расределенные случанйые
	величины $X_1,\dots,X_{n}$ 
	имееют распределение Коши, то $\overline{X} = \frac{1}{n}\sum_{i = 1}^{n} X_{i}$
\end{enumerate}
Доказать дома $n = 2,c=1,\alpha = 0$
\subsection{Распределения Рэлея}
\begin{equation}
f(x) = 
\begin{cases}
	2 \lambda x e ^{-\lambda x^2} , x\ge 0\\
	0 , x < 0
\end{cases}
( \lambda  > 0 )
\end{equation} 
\begin{equation}
\int 2 \lambda x e^{-\lambda x^2} dx = 
\int \lambda e^{-\lambda x^2} d x^2 =
- e^{-\lambda x^2} + C
\end{equation} 
\begin{equation}
\int\limits_{0}^{x} f(x)  = -e^{-\lambda x^2} + 1
\end{equation} 
\begin{equation}
F(X) = 
\begin{cases}
	1  - e^{- \lambda x^2} x\ge 0\\
	0 , x< 0
\end{cases}
\end{equation} 
\begin{equation}
	\begin{split}
	f(x)' = 
	2\lambda(e^{-\lambda x^2} + x*(-\lambda 2x *e^{-\lambda x^2})) = 
	2 \lambda (e^{-\lambda x^2} - 2\lambda x^2 *e^{-\lambda x^2}) = \\
	2\lambda* e^{-\lambda x^2} (1 - 2\lambda x^2)
	\end{split}
\end{equation} 
$y = 0$ горизонтальная асимптота при $x \to +\infty$
\begin{equation}
	\int 2 \lambda x^2 e^{-1}
\end{equation} 
\subsection{Распредления для статов}
\subsubsection{Распределение хи квадрат с m степенями свободы}
\begin{definition}
	Пусть случайные величны $X_1,X_2,\dots,X_{m} \sim N(0,1)$ и независимы $Z = \sum_{i=1}^{M} X_{i}^2$
	\begin{equation}
	\chi^2_{m}
	\end{equation} 
\end{definition}
\begin{equation}
f_{\chi_{m}^2}(x) = 0 , x<0
\end{equation} 
\begin{equation}
f_{\chi_{m}^2}(x) = \frac{1}{2^{\frac{m}{2}} \Gamma(\frac{M}{2})}
x
\end{equation} 
\begin{equation}
M(\chi_{M}^2) = m , D(\chi_{m} ^2) =  2m
\end{equation} 
\subsection{Распеределение Стьюдента с $m$ степенями свободы}
\begin{definition}
	Случайнык величины $X_0 \dots X_{m} \sim N(0,1)$ 
	и независимы 
	\begin{equation}
	Z = \frac{X_0}{\sqrt{\frac{1}{m} \sum_{i=1}^{m}X_{i}^2} }
	\end{equation} 
	\begin{equation}
	Z = t_{m}
	\end{equation} 
\end{definition}
\begin{equation}
f_{t_{m}}(x)  = \frac{1}{\sqrt{\pi m} } \frac{\Gamma(\frac{m+1}{2})}{\Gamma(\frac{m}{2})} * \left(1 + \frac{x^2}{m}\right)^{- \frac{m+1}{2}}
\end{equation} 
Это четная унимодальная $(Mo(t_{m}) = 0)$ функция
\begin{equation}
t_{m} = \frac{X_0}{\sqrt{\frac{\chi_{m}^2}{m}} }
\end{equation} 
\begin{equation}
M(t_{m}) = Mo(t_{m}) = me(t_{m}) = 0
\end{equation} 
\begin{equation}
D(t_{m}) =  \frac{m}{m - 2} , m > 2
\end{equation} 
\subsubsection{Раcпределение Фишера-Снедекора}
\begin{equation}
F(m_1,m_2)
\end{equation} 
\begin{definition}
	Даны случайные величины $X_1,X_2,\dots X_{m_1}, Y_1,Y_2,\dots,Y_{m_2} \sim N(0,1)$
	\begin{equation}
	Z = \frac{\frac{1}{m_1} \sum_{i=1}^{m_1} X_{i}^{m_1}}{\frac{1}{m_2} \sum_{i=1}^{m_2}Y^2_{i}}
	\end{equation} 
\end{definition}
\begin{equation}
f_{F_{m_1,m_2}}(x) =
\frac{\Gamma(\frac{m_1 + m_2}{2}) * m_1^{\frac{m_1}{2}}*m_2^{\frac{m_2}{2}}}{\Gamma(\frac{m_1}{2}) \Gamma(\frac{m_2}{2})}
* \frac{x^{\frac{m_1}{2} - 1}}{(m_1 x + m_2)^{\frac{m_1+m_2}{2}}}
\end{equation} 
\begin{equation}
	f_{F_{m_1,m_2}}(x) = 0 , x < 0
\end{equation} 
\begin{equation}
F_{m_1,m_2} = \frac{\frac{1}{m_1} \chi^2_{m_1}}{\frac{1}{m_2}\chi^2_{m_2}}
\end{equation} 
\begin{equation}
\frac{1}{F_{m_1,m_2}} \sim F_{m_2, m_1}
\end{equation} 
\begin{equation}
M(F_{m_1,m_2}) = \frac{m_2}{m_2-1}
\end{equation} 
\begin{equation}
D(m_1,m_2) = \frac{2m_2 ^2 (m_1 + m_2 - 2)}{m_1 (m_2 - 2) ^2 (m_2 - 4)}
\end{equation} 
\begin{equation}
Mo(F_{m_1,m_2}) = \frac{(m_1 - 2)m_2}{m_1 (m_2 + 2)}
\end{equation} 
Пусть $\Omega = \{\omega_1,\omega_2,\dots \omega_{j}\}$
\begin{equation}
P(\omega_{i_1},\dots \omega_{i_{n}}) = \prod_{j = 1}^{n} p_{i_{j}}
\end{equation} 
Рассмотрим последоваьельность
случайных зависимых  величин

Введем дискретное время $t$ и 
случайную величину  $\xi_{t}(\omega)$ 
значение которой определяют в каком состояни
находился объек во время $t$ 
 в любой следущий момент времени объект может сменить 
 состояние
\section{Определение цеи Маркова}
\begin{definition}
	Состояния объекта в момент $t$ 
	характеризуется ограниченной памятью
	 \begin{equation}
		 P(\xi_{t} = j \mid \xi_{1} = 1 , \xi_{t-1} = i) = P(\xi_{t} = j | \xi_{t- 1} = i)
	\end{equation} 
	Это зависимость марковского типа. Такие зависиости наываются цепями Маркова

	Если дополнительно предположить что
	$p^{(1)}_{ij} = P(\xi_{t} = j \mid \xi_{t-1} =i)$ 
	независят от $t$ то такая цепь называется однородной
\end{definition}
\begin{definition}
	Последоватльеность случайных величин $\xi_{1},\xi_2,\dots$ любая из которых может принимать конечное число значений
	$x^{0}_{1},\dots_{j}^{0}$ называется однородной цепь Маркова, если
	\begin{equation}
	P(\xi_1 = x^{0}_{i_1} \dots \xi_{t} = x_{i_{t}}^{0}) 
	\end{equation} 
\end{definition}
\begin{corollary}
	В общем случае можно рассмотреть  дискретное вероятностное
	простанство с счетным множеством исходов
\end{corollary}
\begin{theorem}
	\begin{enumerate}
		\item  $\sum_{i_{1}} \sum_{i_2} \dots \sum_{i_{t}} p_{i_1} p_{i_1 i_2} \dots p_{i_{t-1}i_{t}} = 0$
	\end{enumerate}
\end{theorem}
\subsection{Основные характеристики цепей Маркова}
Исходные характеристики
\begin{enumerate}
	\item вектор вероятностей начального
		распределения $p = (p_1,p_2,\dots,p_{j})^{T}$
	 \item Матрица $P$ переходных веоятностей  $p_{ij}$
\end{enumerate}
Производные характеристики
\begin{enumerate}
	\item  Вероятность перехода из
		состояния $i$ в состояние  $j$ за
		 $t$ тактов времении:
		  \begin{equation}
			  p_{ij}^{(t)} = 
			  \sum_{q = 1}^{J}p_{iq}^{(t-1)} p_{qj}
		 \end{equation} 
		Если обозначить $P^{q}$ 
		матрица перехода за q
		шагов то эта формула в матричнос виде
		\begin{equation}
		P^{(t)}  =P^{(t-1)}p
		\end{equation} 
		\begin{equation}
		P^{(t)} = P^{t}
		\end{equation} 
	\item Безуслованя веростноять $p_{j}^{(t)}$ 
		того, что объект в 
		момент времени $t$ находится в состоянии  $k$:
		 \begin{equation}
		p_{j}^{t} = \sum_{i =1}^{j} p_{i} p_{ij}^{(t-1)}
		\end{equation} 
		вероятность $p_{ij}^{(t-1)}$ 
		образуют $j$-ый столбец матрицы  $P^{(t-1)}$
	\item Вероятность первого возарвщения объекта
		в заданное состояние
		обозначается
		\begin{equation}
		f^{t}_{jj}A = P\left(
		\xi_{t+1} = j; \xi_{t} \neq j;\xi_{t-1} \neq j \dots  \xi_{2} \neq j \mid \xi_{i} = j
		\right)
		\end{equation} 
		Вероятность первого возвращаения в состояние $j$ через  $t$ шагов
		\begin{equation}
		f^{(t)}_{jj} =  \sum_{t=1}^{\infty} f_jj^{(t)}
		\end{equation} 
		Вероятность того что объект когда нибудь
		вернется в состояние $j$

		 \begin{equation}
			 \mu_{jj} = \sum_{t = 1}^{\infty} t f_{jj}^{(t)}
		\end{equation} 

среднее время первого возвращения в состояние $j$ при условии  $f_{jj} = 1$
\end{enumerate}
\subsection{Классификация состоянийи}
\begin{definition}
	Состояние $j$ 
	называется достижимым из состояни  $j$<
	если  $\exists  t_0 \ge  1$  $p_{ij}^{(t_0)} > 0$
\end{definition}
\begin{definition}
	Состояние $i$ называют поглощающим
	если из него не может быть достигнуто никакое другое состояние цепи
\end{definition}
\begin{definition}
	Множество состояниий называется поглащаюшим или замкнутым,есл никакое состояние вне $C$ не может быть достигнуто
	ни пз кого состоянмя вхоядщего в  $C$
\end{definition}
\begin{definition}
	Состояние называется возвратным, если, отпавляюсь от него обхект с вероятность 1 когда нибудь в него вернется
\end{definition}
\subsection{Классификация цепей}
\end{document}
